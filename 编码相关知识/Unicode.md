[TOC]

# Unicode

Unicode ，万国码，国际码，统一码，单一码。是计算机科学领域里的一项业界标准。它对世界上大部分的文字系统进行了整理、编码，使得计算机可以用更为简单的方式来呈现和处理文字。

> 其中的 Uni，指 Unique，Universal，and Uniform。

## 起源和发展

计算机没办法直接处理文本，它只和数字打交道。为了在计算机里用数字表示文本，我们指定了一个从字符到数字的映射，这个映射就是编码（encoding）。

计算机可以表示的字符组成了一个集合，这个集合我们称之为字符集。

和数学中定义集合时无序的不同，字符集中的每一个字符都拥有一个唯一且不和其他字符重复的序号，作为在这个字符集里的位置的标识。

> ??? 字符代码和字符编码的概念

### 标准信息交换

计算机字符编码，最初使用的是 ASCII 码（ America Standard Code for Information Interchange ，美国标准信息交换码）。每个字符用一个字节表示。8 位中用了 7 位来保存 128 中字符对应的二进制代码，最后一位作为奇偶校验。之所以要有这个标准，是因为计算机只能处理 0 和 1，在传输和保存字符时，传输和保存的实际上是比特流而非字符本身。计算机需要一套二进制代码和字符直接的一一映射关系，使得计算机能够在读取到特定的比特流时，能够把这个比特流识别成一个个的字符，在存储字符时，也能够按照这个规则把每个字符保存为可被识别的二进制代码。如果这个映射是不唯一的，那么在不同设计的计算机上进行信息交互时，就会出问题（计算机 A 能读到计算机 B 传过来的正确的比特流，但是 A 无法还原比特流包含的信息）。因此信息交互时要有一个统一的标准，保证各方的信息在相互交换之后可以正常通行，美国国家标准协会（ American National Standard Institute，ANSI）据此需求设定 ASCII 码，规定了所有字符交互时的二进制代码和字符之间的对应关系，因此 ASCII 码叫做标准信息交换码。

由于 ASCII 码的设计只考虑了英语，故只用了 8 位作为单元，最多表示 256 种字符，因此在全球推广时遇到了很大的尴尬，ASCII 的先天缺陷使其无法克服字符不够用这种障碍。在计算机推广到全世界的初期，全世界都遇到了 ASCII 编码无法映射本民族语言文字的问题。因此当时全世界各个地区都在根据自己的需求拓展字符编码标准。由于传输和保存字符本质上处理的全部都是比特流，美国国家标准协会制定了 ASCII，提出了英语和二进制码的对应关系，建立信息的交互标准，那其他国家自然也可以自己设定规则建立本国语言和二进制代码之间的对应关系，从而满足本国语言在计算机上的交互需求。

> 我们国家自 1980 年就有自己的 GB2312 标准（字符编码与代码依旧一致），简单来说就是在兼容 ASCII 的前提下，建立了 16 位的字符集，定义了二进制代码和中文的映射关系，用两个字节表示一个汉子，字符编码直接就用字符代码的值。由于两个字节就是 16 位，这样的字符集理论上最多可以包含 65536 个字符，基本可以满足汉语的正常交互需求。这一套标准不断进行更新，直至今天 Windows 10 简体中文版（大陆发型）的记事本的默认保存编码，ANSI，使用的字符编码就是我过的自定的国家标准。ANSI 旨在解决这样一种情况：Windows 中或许要碰到那些几十年前写的老文档，那么系统保留以往的字符编码方式从而能够正确打开老文档是必要的。ANSI 这种默认编码，根据各个国家和地区历史上自己定义的字符集，地区之间不统一，大陆时国家标准总局发布的国家标准（GB），台湾的繁体中文版则是 Big 5。

而在几十年前，情况要复杂的多，因为各个国家各行其是，哪怕是台湾和大陆这样使用同一语言的地区，由于政府不同，也建立了两套不一样的字符编码标准。台湾的数据文档在大陆打开，由于大陆在手的计算机大概不会预装台湾的编码标准，大陆就无法正确读取台湾文档中的字符。类似的问题在全球广泛出现，使得信息在跨国跨语言时的交互非常麻烦。在出版业则更加麻烦，出版业终归会有一个在文档里需要处理很多种语言的需求，各个语言的编码标准完全不同（甚至不同语言中的字符编码时重叠的），这就让同时要处理多种语言的出版业很难办。因为从上世纪八十年代初开始，多语言编码方案就开始进入行业，例如 IBM 和施乐公司都有多语言编码的产品。各个国家都要用自算计，各个国家独立高处的字符编码标准会在通用性上有很大的麻烦，那么，应该建立一套全球统一的编码系统，包含所有国家的文字字符，全球所有的计算机都应该只用这一套标准，从而实现标准信息交换，这样全球传输都不会有任何字符无法识别的问题。

### 16 位与 32 位的纷争

要容纳全球松油的文字字符，字符集要拓展，按照计算机的习惯，存储单元都是 2 的幂指数大小的。那么应该是拓展到一个字符两个字节，还是四个字节？4 个字节和 2 个字节反应在文档上是差整整一倍的大小，当年不像现在，存储对大部分人来说便宜的跟不要钱一样，网速又很快，网络中的主导流量是多媒体也不是文字。当年不论计算机本身还是存储空间都很昂贵，因此 16 位和 32 位所造成的文档差一倍大小，涉及到了极大的经济利益，标准如果选的有问题，就会在推广上遭到很大阻力，因为能用 16 是最好的。

通用多语言字符标准在研发时，存在两套完全平行的开发研究项目。

#### 美国 施乐公司

第一套是美国，主要是施乐公司主导的，名字叫做 Unicode，建立的字符集称之为 UCS-2（2 比特通用字符集，因为字符代码只有 16 位，所以最多表示 65536 个字符）。Unicode 最初的设计文档除了阐释通用字符编码工程的重要性之外，谈的最关键的问题就是 16 位够不够用，因为哪怕仅仅是在八十年代，对于旨在提供全球统一的字符编码的 Unicode，最多 65536 个字符似乎也是少了一点。

> Unicode 最初的一版是 Unicode 88。Unicode 88 解释了为什么 65536够用，理由在于两点。
>
> * Unicode 88 的制定者说，我们制定的标准是面向未来的，只要加入现在还在用的字符就好，那些正在消亡语言的字符我们觉得就不要放在标准里占空间了，而判定字符是 “Niderb Use” 还是 “Obsolete” 的依据是，是否还出现在当代的出版物中。他们（自称）统计了 1988 年全世界所有发行的报纸和杂志，认为一整年都没有出现在这些出版物的字符是正在消亡的，没有必要加入标准。
> * 对于世界上字符最多的汉子，针对中日韩三国的汉子很多都是类似的特点，因此可以把中日韩类似的汉子统一表示（所谓的“中日韩统一字符”），避免了三国语言的重复输入。
>
> 这两个标准设定后，符合标准要求的，全球语言总字符数少于 2 的 14次方个，16 位绰绰有余，因此 Unicode 88 标准非常慷慨，有一版的空间是留给用户自定义和将来标准补充的，整个空间显得特别空旷。这种标准提出后就经美国强力推广。
>
> 美国人的标准看似很有道理，事实上拉丁语系国家也不会觉得有什么问题，但由于侵犯了东亚三国的利益，中国人，日本人和韩国人是无法接受的。Unicode 一开始给了汉字两万多个字符，日常使用绰绰有余，矛盾主要出在一些不太常用的字和古文中个钟及其罕见的字要不要保留，中日韩三国同属汉子文化圈，汉子能在通用的字符编码中保留多少，直接关乎中华文明，日本文明和韩国文明的古代文化在电子信息时代中能不能被保留下来（字都打不出来还谈什么保存）。在 Unicode 标准的综述中，一边说 Unicode 要成为通用标准编码，一边觉得 32 位太占空间了没人会用所以强行上 16 位，但 16 位本来就是没办法容纳所有字符的。

#### 瑞士日内瓦国际标准组织 ISO

